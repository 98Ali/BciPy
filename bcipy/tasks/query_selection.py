""" Query selection module. Each query method is a class to keep track of the
 history. """

import numpy as np
import random

eps = np.power(.1, 5)  # a small number to avoid numerical issues


class RandomQuery(object):
    """ Given the final posterior selects the N most likely options to be
        queried.
        Attr:
            len_alp(int): Length of the alphabet. Query selection returns
                integers as queries, each corresponding to the location of the
                query to be selected
            len_query(int): number of queries in the scheduled query
        Functions:
            reset():
                this selection method is memoryless, therefore this is void\
            update_query():
                updates the querying method and picks the particular query
        """

    def __init__(self, len_alp, len_query=4):
        self.alp = list(range(len_alp))
        self.len_query = len_query

    def reset(self):
        """ This object does not require history. Reset is a void function. """
        tmp = None

    def update_query(self, p):
        """ with the final belief over the system, updates the querying method
            and generates len_query most likely queries.
            Args:
                p(list[float]): list of probability distribution over state
                    estimates
            Return:
                pos_query(list[int]): positions of queries in alphabet """
        tmp = [i for i in self.alp]
        pos_query = random.sample(tmp, self.len_query)

        return pos_query


class NBestQuery(object):
    """ Given the final posterior selects the N most likely options.
        Attr:
            len_alp(int): Length of the alphabet. Query selection returns
                integers as queries, each corresponding to the location of the
                query to be selected
            len_query(int): number of queries in the scheduled query
        Functions:
            reset():
                this selection method is memoryless, therefore this is void\
            update_query():
                updates the querying method and picks the particular query
        """

    def __init__(self, len_alp, len_query=4):
        self.alp = list(range(len_alp))
        self.len_query = len_query

    def reset(self):
        """ This object does not require history. Reset is a void function. """
        tmp = None

    def update_query(self, p):
        """ with the final belief over the system, updates the querying method and
            generates len_query most likely queries.
            Args:
                p(list[float]): list of probability distribution over state
                    estimates
            Return:
                pos_query(list[int]): positions of queries in alphabet """
        tmp = [i for i in self.alp]
        pos_query = best_selection(tmp, p, self.len_query)

        return pos_query


class MomentumQuerying(object):
    """ picks arms in multi armed bandit(MAB) with the momentum reward.
        reward is convex combination of the momentum of a particular query and
        the entropy. given the rewards makes greedy arm selection.
        Attr:
            len_alp(int): Length of the alphabet. Query selection returns
                integers as queries, each corresponding to the location of the
                query to be selected
            lam(float): in [0,1] convex combination parameter
            gam(float): in [0,1] history decay rate for momentum
            momentum(ndarray[float]): momentum values for each element
            prob_history(list[list[float]]): probability values for each step
                in the history for each element in the alphabet
            last_query(list[str]): final query generated by the system
        Functions:
            reset():
                resets the system memory
                """

    def __init__(self, len_alp, len_query=4, gam=.9, lam=.9):
        self.alp = list(range(len_alp))
        self.lam = lam
        self.gam = gam
        self.len_query = len_query
        self.momentum = np.zeros(len(self.alp))
        self.prob_history = []
        self.last_query = []

    def reset(self, lam=.9):
        """ resets the history related items in the query method
            Args:
                lam(float): in [0,1] convex combination parameter """
        self.lam = lam
        self.momentum = np.zeros(len(self.alp))
        self.prob_history = []

    def update_query(self, p):
        """ with the final belief over the system, updates the querying method
            and generates len_query most likely queries.
            Args:
                p(list[float]): list of probability distribution over the state
                    estimates
            Return:
                pos_query(list[int]): positions of queries in alphabet """
        tmp = p[:]
        self.prob_history.append(tmp)
        self.update_momentum()

        entropy_term = np.array(tmp) * np.log2(tmp + eps) + (
                1.01 - np.array(tmp)) * (np.log2(1.0 - np.array(tmp) + eps))
        entropy_term[np.isnan(entropy_term)] = 0
        # TODO: Stupid magic number
        reward = (self.lam - 1) * entropy_term + self.lam * self.momentum
        self.update_lam()

        tmp_alp = [i for i in self.alp]
        tmp_query = best_selection(tmp_alp, reward, self.len_query)

        self.last_query = [i for i in tmp_query]

        return self.last_query

    def update_momentum(self):
        """ momentum is updated with the particular probability history of the
            system.
            WARNING!: if called twice without a probability update, will update
            momentum using the same information twice """
        if len(self.prob_history) >= 2:
            # only update momentum for previous terms
            idx_prev_query = [self.alp.index(self.last_query[i]) for i in
                              range(len(self.last_query))]
            self.momentum *= self.gam

            for k in idx_prev_query:
                # momentum = current_mass * mass_displacement
                self.momentum[k] += self.prob_history[-1][k] * np.power(10,
                                                                        5) * (
                                            self.prob_history[-1][k] -
                                            self.prob_history[-2][k])

    def update_lam(self):
        """ Handles the handshaking between two objectives. currently just a
            constant shift with number of queries, should be updated
            logically """
        self.lam = np.max([self.lam - .2, 0])


def best_selection(list_el, val, len_query):
    """ given set of elements and a value function over the set, picks the
        len_query number of elements with the best value.
        Args:
            list_el(list[str]): the set of elements
            val(list[float]): values for the corresponding elements
            len_query(int): number of elements to be picked from the set
        Return:
            query(list[str]): elements from list_el with the best value """
    max_p_val = np.sort(val)[::-1]
    max_p_val = max_p_val[0:len_query]

    query = []
    for idx in range(len_query):
        idx_q = np.where(val == max_p_val[idx])[0][0]
        q = list_el[idx_q]
        val = np.delete(val, idx_q)
        list_el.remove(q)
        query.append(q)

    return query
